library(caret)
dummy_data_def <- read_csv("dummy_data_def.csv")
dummy_data_def = dummy_data_def[,-1]
train = read.csv("train.csv")

train_rows=sample(1:1100, .70*1100)
y=train[,80]
train_set= dummy_data_def[train_rows,]
test_set = dummy_data_def[-train_rows,]
y.train= y[train_rows]
y.test = y[-train_rows]
train_set=as.data.frame(train_set)
test_set=as.data.frame(test_set)
train_set[,"SalePrice"] <- y.train
test_set[,"SalePrice"] <- y.test

fitControl <- trainControl(
  method = "repeatedcv", #10-fold cv repeated 10 times
  number = 10,
  repeats = 10, 
  ###preProcOptions = list(pcaComp = 7),
  verboseIter = TRUE)

model0 <- train(
  SalePrice ~ ., train_set,
  method = "lm",
  ###preProcess=c("center", "scale", "pca"),
  trControl = fitControl
)
pred0=predict(model0, test_set)
error0=(y.test - pred0)
mse0=mean((error0)^2)
#----
model1 <- train(
  SalePrice ~ ., train_set,
  method = "rf",
  trControl = trainControl(
    method = "repeatedcv", number = 10,
    repeats = 1,
    verboseIter = TRUE
  )
)
pred1=predict(model1, test_set)
error1=(y.test - pred1)
mse1=mean((error1)^2)
#-----------
model2 <- train(SalePrice~., train_set, 
                method = "ridge",trControl = fitControl)

pred2=predict(model2, test_set)
error2=(y.test - pred2)
mse2=mean((error2)^2)
#-----
model3 <- train(SalePrice~., train_set, 
                method = "lasso",trControl = fitControl)

pred3=predict(model3, test_set)
error3=(y.test - pred3)
mse3=mean((error3)^2)
#---
model4 <- train(SalePrice~., train_set, 
                method = "enet",trControl = fitControl)

pred4=predict(model4, test_set)
error4=(y.test - pred4)
mse4=mean((error4)^2)
#-----------
model5 <- train(SalePrice~., train_set, 
                method = "gbm",trControl = trainControl(
                  method = "repeatedcv", number = 5, repeats = 3,
                  verboseIter = TRUE))
pred5=predict(model5, test_set)
error5=(y.test - pred5)
mse5=mean((error5)^2)
#xgbDART (Dropouts meet Multiple Additive Regression Tree)
model6 <- train(SalePrice ~ ., data=train_set, 
                method = "xgbDART",trControl = trainControl(
                  method = "cv", number = 5,
                  verboseIter = TRUE))
pred6=predict(model6, test_set)
error6=(y.test - pred6)
mse6=mean((error6)^2)
#xgbTree
model7 <- train(SalePrice~., train_set, 
                method = "xgbTree",trControl = trainControl(
                  method = "cv", number = 5,
                  verboseIter = TRUE))
pred7=predict(model7, test_set)
error7=(y.test - pred7)
mse7=mean((error7)^2)

#xgbLinear
model8 <- train(SalePrice~., train_set, 
                method = "xgbLinear",trControl = trainControl(
                  method = "cv", number = 5,
                  verboseIter = TRUE))
pred8=predict(model8, test_set)
error8=(y.test - pred8)
ms8=mean((error8)^2)
#---------------
plot0=ggplot(test_set,aes(pred0, y.test)) + geom_point(color = "darkred", alpha = 0.5) + 
  geom_smooth(method=lm)+ ggtitle('Linear Regression ') + ggtitle("Linear Regression: Prediction vs Test Data") +
  xlab("Predecited Output ") + ylab("Observed Output")
plot0
plot1=ggplot(test_set,aes(pred0, y.test)) + geom_point(color = "darkred", alpha = 0.5) + 
  geom_smooth(method=lm)+ ggtitle('Random Forest') + ggtitle("Random Forest: Prediction vs Test Data") +
  xlab("Predecited Output ") + ylab("Observed Output")
plot1
plot2=ggplot(test_set,aes(pred2, y.test)) + geom_point(color = "darkred", alpha = 0.5) + 
  geom_smooth(method=lm)+ ggtitle('Ridge') + ggtitle("Ridge: Prediction vs Test Data") +
  xlab("Predecited Output ") + ylab("Observed Output")
plot2
plot3=ggplot(test_set,aes(pred2, y.test)) + geom_point(color = "darkred", alpha = 0.5) + 
  geom_smooth(method=lm)+ ggtitle('Lasso') + ggtitle("Lasso: Prediction vs Test Data") +
  xlab("Predecited Output ") + ylab("Observed Output")
plot3
plot4=ggplot(test_set,aes(pred4, y.test)) + geom_point(color = "darkred", alpha = 0.5) + 
  geom_smooth(method=lm)+ ggtitle('Elastic Net') + ggtitle("Elastic Net: Prediction vs Test Data") +
  xlab("Predecited Output ") + ylab("Observed Output")
plot4
plot5=ggplot(test_set,aes(pred5, y.test)) + geom_point(color = "darkred", alpha = 0.5) + 
  geom_smooth(method=lm)+ ggtitle('Gradient Boosting') + ggtitle("Gradient Boosting: Prediction vs Test Data") +
  xlab("Predecited Output ") + ylab("Observed Output")
plot5
plot6=ggplot(test_set,aes(pred0, y.test)) + geom_point(color = "darkred", alpha = 0.5) + 
  geom_smooth(method=lm)+ ggtitle('Extreme Gradient Boosting') + ggtitle("Extreme Gradient Boosting (DART): Prediction vs Test Data") +
  xlab("Predecited Output ") + ylab("Observed Output")
plot6
plot7=ggplot(test_set,aes(pred0, y.test)) + geom_point(color = "darkred", alpha = 0.5) + 
  geom_smooth(method=lm)+ ggtitle('Extreme Gradient Boosting') + ggtitle("Extreme Gradient Boosting (DART): Prediction vs Test Data") +
  xlab("Predecited Output ") + ylab("Observed Output")
plot7
plot8=ggplot(test_set,aes(pred8, y.test)) + geom_point(color = "darkred", alpha = 0.5) + 
  geom_smooth(method=lm)+ ggtitle('Extreme Gradient Boosting') + ggtitle("Extreme Gradient Boosting (DART): Prediction vs Test Data") +
  xlab("Predecited Output ") + ylab("Observed Output")
plot8

library(gridExtra)
grid.arrange(plot0,plot1,plot2,plot3,plot4,plot5)#,plot6)
grid.arrange(plot0,plot1,plot5)
bbbb=c(mse0,mse1,mse2,mse3,mse4,mse5)






