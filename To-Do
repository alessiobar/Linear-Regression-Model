Data Understanding:
Scegliere qualche metrica per confrontare i modelli (mape... cercare la migliore), e.g. per feature selection co tipo rf 
capire quanto avrebbe fittato
fare una rf al dataset originale e capire quanto verrebbe
Data Cleaning:
  - Remove predictors with more than 15% NA
  - Missing Imputation--> Na from train and test (with data understanding) sostituire con la Mode NON LA MEAN
  - Replace Outlier from train and test (using only data from train)
  - Remove NearZeroVariance columns
  - Normalization(interval) and Centering(i.e. skeweness) CON PREPROCESS DEL CARET
  - Dummy Variable (using OneHot and trying to find better approaches) #meglio sarebbe MCA (tipo pca) ma per le categoriche 
  .. FEATURE ENGINEERING ()

Feture Selection:
  ##- Remove low correlated predictors w.r.t response !!!! non cosideri i gruppi, rf lo potresti peggiorare
  - Merging highly correlated predictors
  - Lasso for selectiong predictors
  - Xgboost for selectiong predictors [dovrebbe funge co anche senza dummy (prova entrambe)
  - Random Forest Predictors Importance SU TUTTO IL TRAIN (p) [funge co anche senza dummy (prova entrambe)
  [di ste ultime tre prova a fare un unione se so poche, intesezione se so troppe]

##{Dimensionality reduction:
 ##- avendo tempo PCA (scegli numero di componenti, della grandezza di quelle della F.S.)}
 
 Models: (capire quali posso fare sulle categoriche)
  - Linear Model
  - Ridge/Lasso/Elastic-net
  fare senza selection delle feature e con e confronta
  - Gradient Boosting Machine
  - Random Forest Predictors Importance SU TUTTO IL TRAIN (p)
  - Xgboosting
 
  Cose:
 Preprocess sul train center scale e volendo pca solo su numeriche, poi da applicare al test tramite il predict() sul train e test.
  -Settare un cazzo di seed
