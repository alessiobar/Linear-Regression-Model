library(caret)
library(ggplot2)
train = read.csv("train.csv")
test = read.csv("test.csv")
miro=train[, (sapply(train, class) == "integer")]
fill.na.num = function(x){
  for(i in 1:length(x)){
    col = x[, i]
    if(sum(is.na(col)) > 0){
      col[is.na(col)] = median(col, na.rm = TRUE)
    }
    x[, i] = col
  } 
  return(x)
}
miro=fill.na.num(miro)
#----------------------------after data is prepared:
model0 <- train(
  SalePrice ~ ., miro,
  method = "lm",
  trControl = trainControl(
    method = "cv", number = 5,
    verboseIter = TRUE
  )
)
pred0=predict(model0, miro)
error0=(miro$SalePrice - pred0)
mean((error0)^2)
#----
model1 <- train(
  SalePrice ~ ., miro,
  method = "rf",
  trControl = trainControl(
    method = "cv", number = 5,
    verboseIter = TRUE
  )
)
pred1=predict(model1, miro)
error1=(miro$SalePrice - pred1)
mean((error1)^2)
#-----------
model2 <- train(SalePrice~., data = miro, 
                method = "ridge",trControl = trainControl(
                  method = "cv", number = 5,
                  verboseIter = TRUE))
pred2=predict(model2, miro)
error2=(miro$SalePrice - pred2)
mean((error2)^2)
#-----
model3 <- train(SalePrice~., data = miro, 
                method = "lasso",trControl = trainControl(
                  method = "cv", number = 5,
                  verboseIter = TRUE))
pred3=predict(model3, miro)
error3=(miro$SalePrice - pred3)
mean((error3)^2)
#---
model4 <- train(SalePrice~., data = miro, 
                method = "enet",trControl = trainControl(
                  method = "cv", number = 5,
                  verboseIter = TRUE))
pred4=predict(model4, miro)
error4=(miro$SalePrice - pred4)
mean((error4)^2)
#-----------
model5 <- train(SalePrice~., data = miro, 
                method = "gbm",trControl = trainControl(
                  method = "cv", number = 5,
                  verboseIter = TRUE))
pred5=predict(model5, miro)
error5=(miro$SalePrice - pred5)
mean((error5)^2)
#xgbDART (Dropouts meet Multiple Additive Regression Tree)
model6 <- train(SalePrice~., data = miro, 
                method = "xgbDART",trControl = trainControl(
                  method = "cv", number = 5,
                  verboseIter = TRUE))
pred6=predict(model6, miro)
error6=(miro$SalePrice - pred6)
mean((error6)^2)
#xgbTree
model7 <- train(SalePrice~., data = miro, 
                method = "xgbTree",trControl = trainControl(
                  method = "cv", number = 5,
                  verboseIter = TRUE))
pred7=predict(model7, miro)
error7=(miro$SalePrice - pred7)
mean((error7)^2)

#xgbLinear
model8 <- train(SalePrice~., data = miro, 
                method = "xgbLinear",trControl = trainControl(
                  method = "cv", number = 5,
                  verboseIter = TRUE))
pred8=predict(model8, miro)
error8=(miro$SalePrice - pred8)
mean((error8)^2)
#---------------
plot0=ggplot(miro,aes(pred0, miro$SalePrice)) + geom_point(color = "darkred", alpha = 0.5) + 
  geom_smooth(method=lm)+ ggtitle('Linear Regression ') + ggtitle("Linear Regression: Prediction vs Test Data") +
  xlab("Predecited Output ") + ylab("Observed Output")
plot0
plot1=ggplot(miro,aes(pred1, miro$SalePrice)) + geom_point(color = "darkred", alpha = 0.5) + 
  geom_smooth(method=lm)+ ggtitle('Random Forest') + ggtitle("Random Forest: Prediction vs Test Data") +
  xlab("Predecited Output ") + ylab("Observed Output")
plot1
plot2=ggplot(miro,aes(pred2, miro$SalePrice)) + geom_point(color = "darkred", alpha = 0.5) + 
  geom_smooth(method=lm)+ ggtitle('Ridge') + ggtitle("Ridge: Prediction vs Test Data") +
  xlab("Predecited Output ") + ylab("Observed Output")
plot2
plot3=ggplot(miro,aes(pred2, miro$SalePrice)) + geom_point(color = "darkred", alpha = 0.5) + 
  geom_smooth(method=lm)+ ggtitle('Lasso') + ggtitle("Lasso: Prediction vs Test Data") +
  xlab("Predecited Output ") + ylab("Observed Output")
plot3
plot4=ggplot(miro,aes(pred4, miro$SalePrice)) + geom_point(color = "darkred", alpha = 0.5) + 
  geom_smooth(method=lm)+ ggtitle('Elastic Net') + ggtitle("Elastic Net: Prediction vs Test Data") +
  xlab("Predecited Output ") + ylab("Observed Output")
plot4
plot5=ggplot(miro,aes(pred5, miro$SalePrice)) + geom_point(color = "darkred", alpha = 0.5) + 
  geom_smooth(method=lm)+ ggtitle('Gradient Boosting') + ggtitle("Gradient Boosting: Prediction vs Test Data") +
  xlab("Predecited Output ") + ylab("Observed Output")
plot5
plot6=ggplot(miro,aes(pred6, miro$SalePrice)) + geom_point(color = "darkred", alpha = 0.5) + 
  geom_smooth(method=lm)+ ggtitle('Extreme Gradient Boosting') + ggtitle("Extreme Gradient Boosting (DART): Prediction vs Test Data") +
  xlab("Predecited Output ") + ylab("Observed Output")
plot6
plot7=ggplot(miro,aes(pred7, miro$SalePrice)) + geom_point(color = "darkred", alpha = 0.5) + 
  geom_smooth(method=lm)+ ggtitle('Extreme Gradient Boosting') + ggtitle("Extreme Gradient Boosting (DART): Prediction vs Test Data") +
  xlab("Predecited Output ") + ylab("Observed Output")
plot7
plot8=ggplot(miro,aes(pred8, miro$SalePrice)) + geom_point(color = "darkred", alpha = 0.5) + 
  geom_smooth(method=lm)+ ggtitle('Extreme Gradient Boosting') + ggtitle("Extreme Gradient Boosting (DART): Prediction vs Test Data") +
  xlab("Predecited Output ") + ylab("Observed Output")
plot8

library(gridExtra)
grid.arrange(plot0,plot1,plot2,plot3,plot4,plot5)#,plot6)
